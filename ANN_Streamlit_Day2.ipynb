{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6J9a0TLiMyY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQbcNS2BiRvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle  # Using the pickle library as requested\n",
        "\n",
        "# Ensure consistent results for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# --- Step 1: Data Loading and Preprocessing (Same as Day 1) ---\n",
        "print(\"--- Step 1: Data Loading and Preprocessing ---\")\n",
        "try:\n",
        "    df = pd.read_csv('/content/Telco_Cusomer_Churn.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found. Please ensure 'WA_Fn-UseC_-Telco-Customer-Churn.csv' is in the same directory.\")\n",
        "    exit()\n",
        "\n",
        "# Handle TotalCharges and split data\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "X = df.drop(columns=['Churn', 'customerID'])\n",
        "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Identify features for preprocessing\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_val_processed = preprocessor.transform(X_val)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "input_shape = X_train_processed.shape[1]\n",
        "\n",
        "print(\"Data preprocessing complete. Proceeding to Day 2 training...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Step 2: Training Three New Models ---\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Model 1: A new simple architecture\n",
        "print(\"\\n--- Model 1: A new simple model ---\")\n",
        "model1_d2 = Sequential([\n",
        "    Dense(20, activation='relu', input_shape=(input_shape,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1_d2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history1_d2 = model1_d2.fit(X_train_processed, y_train,\n",
        "                            epochs=100,\n",
        "                            validation_data=(X_val_processed, y_val),\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "# Model 2: A new intermediate architecture\n",
        "print(\"\\n--- Model 2: A new intermediate model ---\")\n",
        "model2_d2 = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(input_shape,)),\n",
        "    Dropout(0.1),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2_d2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history2_d2 = model2_d2.fit(X_train_processed, y_train,\n",
        "                            epochs=100,\n",
        "                            validation_data=(X_val_processed, y_val),\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "# Model 3: A new advanced architecture\n",
        "print(\"\\n--- Model 3: A new advanced model ---\")\n",
        "model3_d2 = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3_d2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history3_d2 = model3_d2.fit(X_train_processed, y_train,\n",
        "                            epochs=100,\n",
        "                            validation_data=(X_val_processed, y_val),\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Step 3: Evaluate and Select the Best Model ---\n",
        "print(\"\\n--- Step 3: Evaluating and Selecting the Best Model ---\")\n",
        "_, acc1_d2 = model1_d2.evaluate(X_test_processed, y_test, verbose=0)\n",
        "_, acc2_d2 = model2_d2.evaluate(X_test_processed, y_test, verbose=0)\n",
        "_, acc3_d2 = model3_d2.evaluate(X_test_processed, y_test, verbose=0)\n",
        "\n",
        "models = {\n",
        "    \"Model 1\": {\"model\": model1_d2, \"accuracy\": acc1_d2},\n",
        "    \"Model 2\": {\"model\": model2_d2, \"accuracy\": acc2_d2},\n",
        "    \"Model 3\": {\"model\": model3_d2, \"accuracy\": acc3_d2}\n",
        "}\n",
        "\n",
        "best_model_name = max(models, key=lambda name: models[name][\"accuracy\"])\n",
        "best_model = models[best_model_name][\"model\"]\n",
        "best_accuracy = models[best_model_name][\"accuracy\"]\n",
        "\n",
        "print(f\"Model 1 Test Accuracy: {acc1_d2:.4f}\")\n",
        "print(f\"Model 2 Test Accuracy: {acc2_d2:.4f}\")\n",
        "print(f\"Model 3 Test Accuracy: {acc3_d2:.4f}\")\n",
        "print(f\"\\nConclusion: The best model is '{best_model_name}' with an accuracy of {best_accuracy:.4f} on the test set.\")\n",
        "\n",
        "# --- Step 4: Saving the Best Model and Preprocessor ---\n",
        "print(\"\\n--- Step 4: Saving the Best Model and Preprocessor ---\")\n",
        "\n",
        "# The Keras model is saved using its native method\n",
        "best_model.save('best_ann_model.h5')\n",
        "print(\"✅ Best Keras model saved as 'best_ann_model.h5'\")\n",
        "\n",
        "# The preprocessor is saved using the pickle library as requested\n",
        "with open('preprocessor.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)\n",
        "\n",
        "print(\"✅ Preprocessor saved as 'preprocessor.pkl' using pickle\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-uCG_LWiRsB",
        "outputId": "ed45b666-9b26-4d4f-b86d-04b2717f4157"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Data Loading and Preprocessing ---\n",
            "Data preprocessing complete. Proceeding to Day 2 training...\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Model 1: A new simple model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7266 - loss: 0.5376 - val_accuracy: 0.8000 - val_loss: 0.4299\n",
            "Epoch 2/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.4355 - val_accuracy: 0.8114 - val_loss: 0.4183\n",
            "Epoch 3/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4280 - val_accuracy: 0.8123 - val_loss: 0.4149\n",
            "Epoch 4/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4252 - val_accuracy: 0.8152 - val_loss: 0.4136\n",
            "Epoch 5/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.4235 - val_accuracy: 0.8123 - val_loss: 0.4130\n",
            "Epoch 6/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4219 - val_accuracy: 0.8133 - val_loss: 0.4126\n",
            "Epoch 7/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4203 - val_accuracy: 0.8133 - val_loss: 0.4123\n",
            "Epoch 8/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4188 - val_accuracy: 0.8133 - val_loss: 0.4121\n",
            "Epoch 9/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4177 - val_accuracy: 0.8114 - val_loss: 0.4121\n",
            "Epoch 10/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.4167 - val_accuracy: 0.8104 - val_loss: 0.4122\n",
            "Epoch 11/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4158 - val_accuracy: 0.8104 - val_loss: 0.4124\n",
            "Epoch 12/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.4150 - val_accuracy: 0.8123 - val_loss: 0.4127\n",
            "Epoch 13/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4142 - val_accuracy: 0.8114 - val_loss: 0.4129\n",
            "Epoch 14/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4134 - val_accuracy: 0.8095 - val_loss: 0.4132\n",
            "Epoch 15/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4126 - val_accuracy: 0.8095 - val_loss: 0.4135\n",
            "Epoch 16/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4119 - val_accuracy: 0.8104 - val_loss: 0.4140\n",
            "\n",
            "--- Model 2: A new intermediate model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6379 - loss: 0.6244 - val_accuracy: 0.8028 - val_loss: 0.4283\n",
            "Epoch 2/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7846 - loss: 0.4423 - val_accuracy: 0.8028 - val_loss: 0.4160\n",
            "Epoch 3/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4355 - val_accuracy: 0.8076 - val_loss: 0.4128\n",
            "Epoch 4/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.4251 - val_accuracy: 0.8076 - val_loss: 0.4128\n",
            "Epoch 5/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4261 - val_accuracy: 0.8038 - val_loss: 0.4122\n",
            "Epoch 6/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4187 - val_accuracy: 0.8066 - val_loss: 0.4123\n",
            "Epoch 7/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.4212 - val_accuracy: 0.8123 - val_loss: 0.4123\n",
            "Epoch 8/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4179 - val_accuracy: 0.8095 - val_loss: 0.4118\n",
            "Epoch 9/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4166 - val_accuracy: 0.8114 - val_loss: 0.4116\n",
            "Epoch 10/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.4145 - val_accuracy: 0.8114 - val_loss: 0.4116\n",
            "Epoch 11/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.4118 - val_accuracy: 0.8114 - val_loss: 0.4120\n",
            "Epoch 12/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4118 - val_accuracy: 0.8085 - val_loss: 0.4115\n",
            "Epoch 13/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4108 - val_accuracy: 0.8104 - val_loss: 0.4120\n",
            "Epoch 14/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.4088 - val_accuracy: 0.8095 - val_loss: 0.4132\n",
            "Epoch 15/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4093 - val_accuracy: 0.8095 - val_loss: 0.4146\n",
            "Epoch 16/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.4087 - val_accuracy: 0.8076 - val_loss: 0.4146\n",
            "Epoch 17/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.4063 - val_accuracy: 0.8066 - val_loss: 0.4167\n",
            "Epoch 18/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4062 - val_accuracy: 0.8038 - val_loss: 0.4160\n",
            "Epoch 19/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4067 - val_accuracy: 0.8057 - val_loss: 0.4162\n",
            "\n",
            "--- Model 3: A new advanced model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7388 - loss: 0.5117 - val_accuracy: 0.8104 - val_loss: 0.4124\n",
            "Epoch 2/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.4423 - val_accuracy: 0.8199 - val_loss: 0.4091\n",
            "Epoch 3/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.4366 - val_accuracy: 0.8180 - val_loss: 0.4104\n",
            "Epoch 4/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.4295 - val_accuracy: 0.8209 - val_loss: 0.4091\n",
            "Epoch 5/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4238 - val_accuracy: 0.8161 - val_loss: 0.4100\n",
            "Epoch 6/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4225 - val_accuracy: 0.8180 - val_loss: 0.4106\n",
            "Epoch 7/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4211 - val_accuracy: 0.8171 - val_loss: 0.4114\n",
            "Epoch 8/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4158 - val_accuracy: 0.8152 - val_loss: 0.4123\n",
            "Epoch 9/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4157 - val_accuracy: 0.8133 - val_loss: 0.4135\n",
            "Epoch 10/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4162 - val_accuracy: 0.8114 - val_loss: 0.4123\n",
            "Epoch 11/100\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4159 - val_accuracy: 0.8085 - val_loss: 0.4143\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Step 3: Evaluating and Selecting the Best Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Test Accuracy: 0.7867\n",
            "Model 2 Test Accuracy: 0.7877\n",
            "Model 3 Test Accuracy: 0.7810\n",
            "\n",
            "Conclusion: The best model is 'Model 2' with an accuracy of 0.7877 on the test set.\n",
            "\n",
            "--- Step 4: Saving the Best Model and Preprocessor ---\n",
            "✅ Best Keras model saved as 'best_ann_model.h5'\n",
            "✅ Preprocessor saved as 'preprocessor.pkl' using pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axHKMkrbiRpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMzz9SWriRnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbMoAIeriRko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}